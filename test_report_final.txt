============================= test session starts =============================
platform win32 -- Python 3.11.8, pytest-8.4.2, pluggy-1.6.0
rootdir: C:\Users\Usuario\Workspace\01_Proyectos\anclora-nexus\sdd\features\intelligence\tests\test-code
configfile: pytest.ini
plugins: anyio-4.11.0, langsmith-0.6.8, asyncio-1.2.0
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=function, asyncio_default_test_loop_scope=function
collected 64 items

sdd\features\intelligence\tests\test-code\test_governor.py ....F.F....F. [ 20%]
FF...F..                                                                 [ 32%]
sdd\features\intelligence\tests\test-code\test_orchestrator.py ........F [ 46%]
.........                                                                [ 60%]
sdd\features\intelligence\tests\test-code\test_skills.py FF.FFFF..FFF... [ 84%]
....F.....                                                               [100%]

================================== FAILURES ===================================
_________________________ test_evaluate_empty_domains _________________________
sdd\features\intelligence\tests\test-code\test_governor.py:57: in test_evaluate_empty_domains
    assert error is None
E   AssertionError: assert 'GovernorDecision validation failed: domains_used is required' is None
---------------------------- Captured stderr setup ----------------------------
{"timestamp": "2026-02-13T20:37:01.736484+00:00", "level": "INFO", "message": "Governor initialized", "module": "governor", "funcName": "__init__"}
----------------------------- Captured log setup ------------------------------
INFO     intelligence.governor:governor.py:52 Governor initialized
---------------------------- Captured stderr call -----------------------------
{"timestamp": "2026-02-13T20:37:01.737204+00:00", "level": "INFO", "message": "Starting evaluation", "module": "governor", "funcName": "evaluate"}
{"timestamp": "2026-02-13T20:37:01.737204+00:00", "level": "ERROR", "message": "Decision validation failed", "module": "governor", "funcName": "evaluate"}
------------------------------ Captured log call ------------------------------
INFO     intelligence.governor:governor.py:76 Starting evaluation
ERROR    intelligence.governor:governor.py:136 Decision validation failed
_________________________ test_hard_constraint_hc_005 _________________________
sdd\features\intelligence\tests\test-code\test_governor.py:75: in test_hard_constraint_hc_005
    assert "hc_005" in decision.flags[0] or any("hc_005" in f for f in decision.flags)
E   AssertionError: assert ('hc_005' in 'hitl_required=true' or False)
E    +  where False = any(<generator object test_hard_constraint_hc_005.<locals>.<genexpr> at 0x00000171E4BA4040>)
---------------------------- Captured stderr setup ----------------------------
{"timestamp": "2026-02-13T20:37:01.747602+00:00", "level": "INFO", "message": "Governor initialized", "module": "governor", "funcName": "__init__"}
----------------------------- Captured log setup ------------------------------
INFO     intelligence.governor:governor.py:52 Governor initialized
---------------------------- Captured stderr call -----------------------------
{"timestamp": "2026-02-13T20:37:01.748262+00:00", "level": "INFO", "message": "Starting evaluation", "module": "governor", "funcName": "evaluate"}
{"timestamp": "2026-02-13T20:37:01.748262+00:00", "level": "INFO", "message": "Evaluation complete", "module": "governor", "funcName": "evaluate"}
------------------------------ Captured log call ------------------------------
INFO     intelligence.governor:governor.py:76 Starting evaluation
INFO     intelligence.governor:governor.py:139 Evaluation complete
___________________________ test_evaluate_exception ___________________________
sdd\features\intelligence\tests\test-code\test_governor.py:120: in test_evaluate_exception
    decision, error = governor.evaluate(None)
                      ^^^^^^^^^^^^^^^^^^^^^^^
backend\intelligence\components\governor.py:76: in evaluate
    logger.info("Starting evaluation", extra={"correlation_id": correlation_id, "mode": query_plan.mode})
                                                                                        ^^^^^^^^^^^^^^^
E   AttributeError: 'NoneType' object has no attribute 'mode'
---------------------------- Captured stderr setup ----------------------------
{"timestamp": "2026-02-13T20:37:01.762832+00:00", "level": "INFO", "message": "Governor initialized", "module": "governor", "funcName": "__init__"}
----------------------------- Captured log setup ------------------------------
INFO     intelligence.governor:governor.py:52 Governor initialized
______________________ test_recommendation_reframe_only _______________________
sdd\features\intelligence\tests\test-code\test_governor.py:160: in test_recommendation_reframe_only
    assert decision.recommendation == Recommendation.REFRAME
           ^^^^^^^^^^^^^^^^^^^^^^^
E   AttributeError: 'NoneType' object has no attribute 'recommendation'
---------------------------- Captured stderr setup ----------------------------
{"timestamp": "2026-02-13T20:37:01.778036+00:00", "level": "INFO", "message": "Governor initialized", "module": "governor", "funcName": "__init__"}
----------------------------- Captured log setup ------------------------------
INFO     intelligence.governor:governor.py:52 Governor initialized
---------------------------- Captured stderr call -----------------------------
{"timestamp": "2026-02-13T20:37:01.778850+00:00", "level": "INFO", "message": "Starting evaluation", "module": "governor", "funcName": "evaluate"}
{"timestamp": "2026-02-13T20:37:01.778850+00:00", "level": "ERROR", "message": "Governor error during evaluation", "module": "governor", "funcName": "evaluate", "exception": "Traceback (most recent call last):\n  File \"C:\\Users\\Usuario\\Workspace\\01_Proyectos\\anclora-nexus\\backend\\intelligence\\components\\governor.py\", line 86, in evaluate\n    risks = self._assess_risks(query_plan, primary_domain or \"unknown\")\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Usuario\\Workspace\\01_Proyectos\\anclora-nexus\\sdd\\features\\intelligence\\tests\\test-code\\test_governor.py\", line 148, in <lambda>\n    governor._assess_risks = lambda q, d: RiskProfile(\n                                          ^^^^^^^^^^^\nNameError: name 'RiskProfile' is not defined"}
------------------------------ Captured log call ------------------------------
INFO     intelligence.governor:governor.py:76 Starting evaluation
ERROR    intelligence.governor:governor.py:143 Governor error during evaluation
Traceback (most recent call last):
  File "C:\Users\Usuario\Workspace\01_Proyectos\anclora-nexus\backend\intelligence\components\governor.py", line 86, in evaluate
    risks = self._assess_risks(query_plan, primary_domain or "unknown")
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Usuario\Workspace\01_Proyectos\anclora-nexus\sdd\features\intelligence\tests\test-code\test_governor.py", line 148, in <lambda>
    governor._assess_risks = lambda q, d: RiskProfile(
                                          ^^^^^^^^^^^
NameError: name 'RiskProfile' is not defined
_______________________ test_generate_diagnosis_market ________________________
sdd\features\intelligence\tests\test-code\test_governor.py:165: in test_generate_diagnosis_market
    risks = RiskProfile(
            ^^^^^^^^^^^
E   NameError: name 'RiskProfile' is not defined
---------------------------- Captured stderr setup ----------------------------
{"timestamp": "2026-02-13T20:37:01.794822+00:00", "level": "INFO", "message": "Governor initialized", "module": "governor", "funcName": "__init__"}
----------------------------- Captured log setup ------------------------------
INFO     intelligence.governor:governor.py:52 Governor initialized
________________________ test_generate_flags_multiple _________________________
sdd\features\intelligence\tests\test-code\test_governor.py:188: in test_generate_flags_multiple
    risks = RiskProfile(
            ^^^^^^^^^^^
E   NameError: name 'RiskProfile' is not defined
---------------------------- Captured stderr setup ----------------------------
{"timestamp": "2026-02-13T20:37:01.806371+00:00", "level": "INFO", "message": "Governor initialized", "module": "governor", "funcName": "__init__"}
----------------------------- Captured log setup ------------------------------
INFO     intelligence.governor:governor.py:52 Governor initialized
________________________ test_critical_panic_recovery _________________________
sdd\features\intelligence\tests\test-code\test_orchestrator.py:156: in test_critical_panic_recovery
    assert result["processing_status"] == "orchestrator_panic"
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E   TypeError: tuple indices must be integers or slices, not str
---------------------------- Captured stderr setup ----------------------------
{"timestamp": "2026-02-13T20:37:01.870183+00:00", "level": "INFO", "message": "Router initialized", "module": "router", "funcName": "__init__"}
{"timestamp": "2026-02-13T20:37:01.870183+00:00", "level": "INFO", "message": "Governor initialized", "module": "governor", "funcName": "__init__"}
{"timestamp": "2026-02-13T20:37:01.870183+00:00", "level": "INFO", "message": "Synthesizer initialized", "module": "synthesizer", "funcName": "__init__"}
{"timestamp": "2026-02-13T20:37:01.870183+00:00", "level": "INFO", "message": "Orchestrator initialized", "module": "orchestrator", "funcName": "__init__"}
----------------------------- Captured log setup ------------------------------
INFO     intelligence.router:router.py:54 Router initialized
INFO     intelligence.governor:governor.py:52 Governor initialized
INFO     intelligence.synthesizer:synthesizer.py:58 Synthesizer initialized
INFO     intelligence.orchestrator:orchestrator.py:42 Orchestrator initialized
---------------------------- Captured stderr call -----------------------------
{"timestamp": "2026-02-13T20:37:01.889767+00:00", "level": "INFO", "message": "Processing new query", "module": "orchestrator", "funcName": "process_query"}
{"timestamp": "2026-02-13T20:37:01.889767+00:00", "level": "ERROR", "message": "Critical error in pipeline", "module": "orchestrator", "funcName": "process_query", "exception": "Traceback (most recent call last):\n  File \"C:\\Users\\Usuario\\Workspace\\01_Proyectos\\anclora-nexus\\backend\\intelligence\\orchestrator\\orchestrator.py\", line 78, in process_query\n    query_plan, router_error = self.router.route_query(message)\n                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\unittest\\mock.py\", line 1124, in __call__\n    return self._mock_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\unittest\\mock.py\", line 1128, in _mock_call\n    return self._execute_mock_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\unittest\\mock.py\", line 1183, in _execute_mock_call\n    raise effect\nRuntimeError: Unexpected!"}
{"timestamp": "2026-02-13T20:37:01.892841+00:00", "level": "ERROR", "message": "Audit transaction error: not enough values to unpack (expected 2, got 0)", "module": "orchestrator", "funcName": "_save_audit_transaction"}
------------------------------ Captured log call ------------------------------
INFO     intelligence.orchestrator:orchestrator.py:61 Processing new query
ERROR    intelligence.orchestrator:orchestrator.py:160 Critical error in pipeline
Traceback (most recent call last):
  File "C:\Users\Usuario\Workspace\01_Proyectos\anclora-nexus\backend\intelligence\orchestrator\orchestrator.py", line 78, in process_query
    query_plan, router_error = self.router.route_query(message)
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Usuario\AppData\Local\Programs\Python\Python311\Lib\unittest\mock.py", line 1124, in __call__
    return self._mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Usuario\AppData\Local\Programs\Python\Python311\Lib\unittest\mock.py", line 1128, in _mock_call
    return self._execute_mock_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Usuario\AppData\Local\Programs\Python\Python311\Lib\unittest\mock.py", line 1183, in _execute_mock_call
    raise effect
RuntimeError: Unexpected!
ERROR    intelligence.orchestrator:orchestrator.py:213 Audit transaction error: not enough values to unpack (expected 2, got 0)
_________________________ test_lead_intake_happy_path _________________________
sdd\features\intelligence\tests\test-code\test_skills.py:25: in test_lead_intake_happy_path
    result = await run_lead_intake(data, mock_llm_service, mock_supabase_service)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sdd\features\intelligence\skills\lead_intake.py:118: in run_lead_intake
    {validated_input.json(ensure_ascii=False)}
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\..\AppData\Local\Programs\Python\Python311\Lib\site-packages\pydantic\main.py:1317: in json
    raise TypeError('`dumps_kwargs` keyword arguments are no longer supported.')
E   TypeError: `dumps_kwargs` keyword arguments are no longer supported.
---------------------------- Captured stdout call -----------------------------
{"timestamp": "2026-02-13T20:37:01.963765", "level": "INFO", "event_type": "skill_started", "skill": "lead_intake", "version": "1.0.0", "details": {"input_summary": "Juan Perez"}}
{"timestamp": "2026-02-13T20:37:01.966975", "level": "CRITICAL", "event_type": "skill_failed", "skill": "lead_intake", "version": "1.0.0", "details": {"error": "`dumps_kwargs` keyword arguments are no longer supported."}}
_______________________ test_lead_intake_high_priority ________________________
sdd\features\intelligence\tests\test-code\test_skills.py:42: in test_lead_intake_high_priority
    result = await run_lead_intake(data, mock_llm_service, mock_supabase_service)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sdd\features\intelligence\skills\lead_intake.py:118: in run_lead_intake
    {validated_input.json(ensure_ascii=False)}
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\..\AppData\Local\Programs\Python\Python311\Lib\site-packages\pydantic\main.py:1317: in json
    raise TypeError('`dumps_kwargs` keyword arguments are no longer supported.')
E   TypeError: `dumps_kwargs` keyword arguments are no longer supported.
---------------------------- Captured stdout call -----------------------------
{"timestamp": "2026-02-13T20:37:02.171586", "level": "INFO", "event_type": "skill_started", "skill": "lead_intake", "version": "1.0.0", "details": {"input_summary": "Rich Client"}}
{"timestamp": "2026-02-13T20:37:02.172104", "level": "CRITICAL", "event_type": "skill_failed", "skill": "lead_intake", "version": "1.0.0", "details": {"error": "`dumps_kwargs` keyword arguments are no longer supported."}}
_________________________ test_lead_intake_llm_retry __________________________
sdd\features\intelligence\tests\test-code\test_skills.py:60: in test_lead_intake_llm_retry
    result = await run_lead_intake(data, mock_llm_service, mock_supabase_service)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sdd\features\intelligence\skills\lead_intake.py:118: in run_lead_intake
    {validated_input.json(ensure_ascii=False)}
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\..\AppData\Local\Programs\Python\Python311\Lib\site-packages\pydantic\main.py:1317: in json
    raise TypeError('`dumps_kwargs` keyword arguments are no longer supported.')
E   TypeError: `dumps_kwargs` keyword arguments are no longer supported.
---------------------------- Captured stdout call -----------------------------
{"timestamp": "2026-02-13T20:37:02.256422", "level": "INFO", "event_type": "skill_started", "skill": "lead_intake", "version": "1.0.0", "details": {"input_summary": "Retry User"}}
{"timestamp": "2026-02-13T20:37:02.256422", "level": "CRITICAL", "event_type": "skill_failed", "skill": "lead_intake", "version": "1.0.0", "details": {"error": "`dumps_kwargs` keyword arguments are no longer supported."}}
____________________ test_lead_intake_llm_parsing_fallback ____________________
sdd\features\intelligence\tests\test-code\test_skills.py:71: in test_lead_intake_llm_parsing_fallback
    result = await run_lead_intake(data, mock_llm_service, mock_supabase_service)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sdd\features\intelligence\skills\lead_intake.py:118: in run_lead_intake
    {validated_input.json(ensure_ascii=False)}
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\..\AppData\Local\Programs\Python\Python311\Lib\site-packages\pydantic\main.py:1317: in json
    raise TypeError('`dumps_kwargs` keyword arguments are no longer supported.')
E   TypeError: `dumps_kwargs` keyword arguments are no longer supported.
---------------------------- Captured stdout call -----------------------------
{"timestamp": "2026-02-13T20:37:02.294771", "level": "INFO", "event_type": "skill_started", "skill": "lead_intake", "version": "1.0.0", "details": {"input_summary": "Parsing Fail"}}
{"timestamp": "2026-02-13T20:37:02.294771", "level": "CRITICAL", "event_type": "skill_failed", "skill": "lead_intake", "version": "1.0.0", "details": {"error": "`dumps_kwargs` keyword arguments are no longer supported."}}
__________________ test_lead_intake_copy_generation_fallback __________________
sdd\features\intelligence\tests\test-code\test_skills.py:83: in test_lead_intake_copy_generation_fallback
    result = await run_lead_intake(data, mock_llm_service, mock_supabase_service)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sdd\features\intelligence\skills\lead_intake.py:118: in run_lead_intake
    {validated_input.json(ensure_ascii=False)}
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\..\AppData\Local\Programs\Python\Python311\Lib\site-packages\pydantic\main.py:1317: in json
    raise TypeError('`dumps_kwargs` keyword arguments are no longer supported.')
E   TypeError: `dumps_kwargs` keyword arguments are no longer supported.
---------------------------- Captured stdout call -----------------------------
{"timestamp": "2026-02-13T20:37:02.329135", "level": "INFO", "event_type": "skill_started", "skill": "lead_intake", "version": "1.0.0", "details": {"input_summary": "Copy Fail"}}
{"timestamp": "2026-02-13T20:37:02.330321", "level": "CRITICAL", "event_type": "skill_failed", "skill": "lead_intake", "version": "1.0.0", "details": {"error": "`dumps_kwargs` keyword arguments are no longer supported."}}
_____________________ test_lead_intake_audit_log_payload ______________________
sdd\features\intelligence\tests\test-code\test_skills.py:92: in test_lead_intake_audit_log_payload
    await run_lead_intake(data, mock_llm_service, mock_supabase_service)
sdd\features\intelligence\skills\lead_intake.py:118: in run_lead_intake
    {validated_input.json(ensure_ascii=False)}
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\..\AppData\Local\Programs\Python\Python311\Lib\site-packages\pydantic\main.py:1317: in json
    raise TypeError('`dumps_kwargs` keyword arguments are no longer supported.')
E   TypeError: `dumps_kwargs` keyword arguments are no longer supported.
---------------------------- Captured stdout call -----------------------------
{"timestamp": "2026-02-13T20:37:02.365423", "level": "INFO", "event_type": "skill_started", "skill": "lead_intake", "version": "1.0.0", "details": {"input_summary": "Log Test"}}
{"timestamp": "2026-02-13T20:37:02.366011", "level": "CRITICAL", "event_type": "skill_failed", "skill": "lead_intake", "version": "1.0.0", "details": {"error": "`dumps_kwargs` keyword arguments are no longer supported."}}
__________________________ test_prospection_no_leads __________________________
sdd\features\intelligence\tests\test-code\test_skills.py:125: in test_prospection_no_leads
    assert "no_leads" in result["reason"].lower()
E   AssertionError: assert 'no_leads' in 'no active leads found with required priority.'
E    +  where 'no active leads found with required priority.' = <built-in method lower of str object at 0x00000171E4B23930>()
E    +    where <built-in method lower of str object at 0x00000171E4B23930> = 'No active leads found with required priority.'.lower
---------------------------- Captured stdout call -----------------------------
{"timestamp": "2026-02-13T20:37:02.424605", "level": "INFO", "event_type": "skill_started", "skill": "prospection_weekly", "version": "1.0.0", "details": {"data": {}}}
{"timestamp": "2026-02-13T20:37:02.425014", "level": "INFO", "event_type": "prospection_skipped", "skill": "prospection_weekly", "version": "1.0.0", "details": {"reason": "no_leads"}}
_______________________ test_prospection_no_properties ________________________
sdd\features\intelligence\tests\test-code\test_skills.py:134: in test_prospection_no_properties
    assert "no_properties" in result["reason"].lower()
E   AssertionError: assert 'no_properties' in 'no available properties found for matching.'
E    +  where 'no available properties found for matching.' = <built-in method lower of str object at 0x00000171E4B235D0>()
E    +    where <built-in method lower of str object at 0x00000171E4B235D0> = 'No available properties found for matching.'.lower
---------------------------- Captured stdout call -----------------------------
{"timestamp": "2026-02-13T20:37:02.439729", "level": "INFO", "event_type": "skill_started", "skill": "prospection_weekly", "version": "1.0.0", "details": {"data": {}}}
{"timestamp": "2026-02-13T20:37:02.439729", "level": "INFO", "event_type": "prospection_skipped", "skill": "prospection_weekly", "version": "1.0.0", "details": {"reason": "no_properties"}}
____________________ test_prospection_llm_timeout_fallback ____________________
sdd\features\intelligence\tests\test-code\test_skills.py:141: in test_prospection_llm_timeout_fallback
    result = await run_prospection_weekly({}, mock_llm_service, mock_supabase_service)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sdd\features\intelligence\skills\prospection_weekly.py:134: in run_prospection_weekly
    matching_raw = await _call_llm_with_retry(llm.analyze, matching_prompt)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sdd\features\intelligence\skills\prospection_weekly.py:69: in _call_llm_with_retry
    raise last_error
sdd\features\intelligence\skills\prospection_weekly.py:63: in _call_llm_with_retry
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\..\AppData\Local\Programs\Python\Python311\Lib\unittest\mock.py:2237: in _execute_mock_call
    raise effect
sdd\features\intelligence\skills\prospection_weekly.py:63: in _call_llm_with_retry
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\..\AppData\Local\Programs\Python\Python311\Lib\unittest\mock.py:2237: in _execute_mock_call
    raise effect
sdd\features\intelligence\skills\prospection_weekly.py:63: in _call_llm_with_retry
    return await func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
..\..\..\AppData\Local\Programs\Python\Python311\Lib\unittest\mock.py:2237: in _execute_mock_call
    raise effect
E   Exception: LLM Timeout
---------------------------- Captured stdout call -----------------------------
{"timestamp": "2026-02-13T20:37:02.457956", "level": "INFO", "event_type": "skill_started", "skill": "prospection_weekly", "version": "1.0.0", "details": {"data": {}}}
{"timestamp": "2026-02-13T20:37:02.458517", "level": "WARNING", "event_type": "llm_retry", "skill": "prospection_weekly", "version": "1.0.0", "details": {"attempt": 1, "error": "LLM Timeout"}}
{"timestamp": "2026-02-13T20:37:02.966490", "level": "WARNING", "event_type": "llm_retry", "skill": "prospection_weekly", "version": "1.0.0", "details": {"attempt": 2, "error": "LLM Timeout"}}
{"timestamp": "2026-02-13T20:37:03.974652", "level": "WARNING", "event_type": "llm_retry", "skill": "prospection_weekly", "version": "1.0.0", "details": {"attempt": 3, "error": "LLM Timeout"}}
{"timestamp": "2026-02-13T20:37:05.984044", "level": "CRITICAL", "event_type": "skill_failed", "skill": "prospection_weekly", "version": "1.0.0", "details": {"error": "LLM Timeout"}}
___________________________ test_recap_llm_fallback ___________________________
sdd\features\intelligence\tests\test-code\test_skills.py:224: in test_recap_llm_fallback
    assert "Normalidad" in result["luxury_summary"]
E   AssertionError: assert 'Normalidad' in 'Resumen semanal de Anclora Nexus: Actividad estable en la zona suroeste. Los sistemas de prospecci¾n y gesti¾n de leads operan con normalidad.'
---------------------------- Captured stdout call -----------------------------
{"timestamp": "2026-02-13T20:37:06.424319", "level": "INFO", "event_type": "skill_started", "skill": "recap_weekly", "version": "1.0.0", "details": {"data": {}}}
{"timestamp": "2026-02-13T20:37:06.424319", "level": "DEBUG", "event_type": "data_collection_started", "skill": "recap_weekly", "version": "1.0.0", "details": {"days": 7}}
{"timestamp": "2026-02-13T20:37:06.424319", "level": "WARNING", "event_type": "recap_parsing_failed", "skill": "recap_weekly", "version": "1.0.0", "details": {"error": "Expecting value: line 1 column 1 (char 0)"}}
{"timestamp": "2026-02-13T20:37:06.424319", "level": "INFO", "event_type": "skill_completed", "skill": "recap_weekly", "version": "1.0.0", "details": {"new_leads": 0, "duration_ms": 0.0}}
============================== warnings summary ===============================
backend\intelligence\models.py:16
  C:\Users\Usuario\Workspace\01_Proyectos\anclora-nexus\backend\intelligence\models.py:16: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
    Base = declarative_base()

..\..\..\AppData\Local\Programs\Python\Python311\Lib\site-packages\_pytest\config\__init__.py:1474
  C:\Users\Usuario\AppData\Local\Programs\Python\Python311\Lib\site-packages\_pytest\config\__init__.py:1474: PytestConfigWarning: Unknown config option: env
  
    self._warn_or_fail_if_strict(f"Unknown config option: {key}\n")

test_skills.py::test_lead_intake_happy_path
test_skills.py::test_lead_intake_high_priority
test_skills.py::test_lead_intake_llm_retry
test_skills.py::test_lead_intake_llm_parsing_fallback
test_skills.py::test_lead_intake_copy_generation_fallback
test_skills.py::test_lead_intake_audit_log_payload
test_skills.py::test_lead_intake_critical_failure
  C:\Users\Usuario\Workspace\01_Proyectos\anclora-nexus\sdd\features\intelligence\skills\lead_intake.py:118: PydanticDeprecatedSince20: The `json` method is deprecated; use `model_dump_json` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/
    {validated_input.json(ensure_ascii=False)}

test_skills.py::test_prospection_happy_path
test_skills.py::test_prospection_complex_matching
test_skills.py::test_prospection_complex_matching
  C:\Users\Usuario\Workspace\01_Proyectos\anclora-nexus\sdd\features\intelligence\skills\prospection_weekly.py:155: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/
    {json.dumps([m.dict() for m in matchings], ensure_ascii=False)}

test_skills.py::test_prospection_happy_path
test_skills.py::test_prospection_matching_parsing_error
test_skills.py::test_prospection_complex_matching
test_skills.py::test_prospection_supabase_call
  C:\Users\Usuario\Workspace\01_Proyectos\anclora-nexus\sdd\features\intelligence\skills\prospection_weekly.py:177: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/
    return result.dict()

test_skills.py::test_recap_happy_path
test_skills.py::test_recap_empty_data
test_skills.py::test_recap_db_failure_graceful
test_skills.py::test_recap_llm_fallback
test_skills.py::test_recap_high_priority_highlight
test_skills.py::test_recap_execution_metric_calc
test_skills.py::test_recap_duration_logging
  C:\Users\Usuario\Workspace\01_Proyectos\anclora-nexus\sdd\features\intelligence\skills\recap_weekly.py:185: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/
    return result.dict()

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ===========================
FAILED sdd\features\intelligence\tests\test-code\test_governor.py::test_evaluate_empty_domains
FAILED sdd\features\intelligence\tests\test-code\test_governor.py::test_hard_constraint_hc_005
FAILED sdd\features\intelligence\tests\test-code\test_governor.py::test_evaluate_exception
FAILED sdd\features\intelligence\tests\test-code\test_governor.py::test_recommendation_reframe_only
FAILED sdd\features\intelligence\tests\test-code\test_governor.py::test_generate_diagnosis_market
FAILED sdd\features\intelligence\tests\test-code\test_governor.py::test_generate_flags_multiple
FAILED sdd\features\intelligence\tests\test-code\test_orchestrator.py::test_critical_panic_recovery
FAILED sdd\features\intelligence\tests\test-code\test_skills.py::test_lead_intake_happy_path
FAILED sdd\features\intelligence\tests\test-code\test_skills.py::test_lead_intake_high_priority
FAILED sdd\features\intelligence\tests\test-code\test_skills.py::test_lead_intake_llm_retry
FAILED sdd\features\intelligence\tests\test-code\test_skills.py::test_lead_intake_llm_parsing_fallback
FAILED sdd\features\intelligence\tests\test-code\test_skills.py::test_lead_intake_copy_generation_fallback
FAILED sdd\features\intelligence\tests\test-code\test_skills.py::test_lead_intake_audit_log_payload
FAILED sdd\features\intelligence\tests\test-code\test_skills.py::test_prospection_no_leads
FAILED sdd\features\intelligence\tests\test-code\test_skills.py::test_prospection_no_properties
FAILED sdd\features\intelligence\tests\test-code\test_skills.py::test_prospection_llm_timeout_fallback
FAILED sdd\features\intelligence\tests\test-code\test_skills.py::test_recap_llm_fallback
================= 17 failed, 47 passed, 23 warnings in 17.28s =================
